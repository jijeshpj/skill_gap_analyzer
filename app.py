# 1. ‡¥Ü‡¥µ‡¥∂‡µç‡¥Ø‡¥Æ‡¥æ‡¥Ø ‡¥≤‡µà‡¥¨‡µç‡¥∞‡¥±‡¥ø‡¥ï‡µæ ‡¥á‡¥±‡¥ï‡µç‡¥ï‡µÅ‡¥Æ‡¥§‡¥ø ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï
import streamlit as st
import PyPDF2
import spacy
import os
from spacy.matcher import Matcher 

# ---------------------------------
# st.set_page_config() ‡¥è‡¥±‡µç‡¥±‡¥µ‡µÅ‡¥Ç ‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡µΩ
# ---------------------------------
st.set_page_config(page_title="Skill Gap Analyzer", layout="wide")

# ... (Import ‡¥ï‡¥Æ‡¥æ‡µª‡¥°‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç st.set_page_config() ‡¥â‡¥Ç ‡¥∂‡¥∞‡¥ø‡¥Ø‡¥æ‡¥£‡µç) ...

# ... (Import ‡¥ï‡¥Æ‡¥æ‡µª‡¥°‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç st.set_page_config() ‡¥â‡¥Ç ‡¥∂‡¥∞‡¥ø‡¥Ø‡¥æ‡¥£‡µç) ...

# ---------------------------------
# 3. spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡¥ø‡¥Ç‡¥ó‡µç (Download on Demand)
# ---------------------------------

# ... (‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ ‡¥≠‡¥æ‡¥ó‡¥Ç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥Æ‡¥ø‡¥≤‡µç‡¥≤) ...

# ... (‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ ‡¥≠‡¥æ‡¥ó‡¥Ç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥Æ‡¥ø‡¥≤‡µç‡¥≤) ...

# ... (‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ ‡¥≠‡¥æ‡¥ó‡¥Ç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥Æ‡¥ø‡¥≤‡µç‡¥≤) ...
# ... (‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ ‡¥≠‡¥æ‡¥ó‡¥Ç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥Æ‡¥ø‡¥≤‡µç‡¥≤) ...

# ---------------------------------
# 3. spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡¥ø‡¥Ç‡¥ó‡µç (GitHub Repository-‡¥Ø‡¥ø‡µΩ ‡¥®‡¥ø‡¥®‡µç‡¥®‡µç ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ)
# ---------------------------------

# @st.cache_resource  # üö® ‡¥à ‡¥≤‡µà‡µª ‡¥ï‡¥Æ‡µª‡µç‡¥±‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï‡¥Ø‡µã ‡¥®‡µÄ‡¥ï‡µç‡¥ï‡¥Ç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï‡¥Ø‡µã ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï üö®
# ... (‡¥Æ‡µÅ‡¥ï‡¥≥‡¥ø‡¥≤‡µÅ‡¥≥‡µç‡¥≥ import ‡¥ï‡¥Æ‡¥æ‡µª‡¥°‡µÅ‡¥ï‡µæ ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡¥Æ‡¥ø‡¥≤‡µç‡¥≤) ...

# ---------------------------------
# 3. spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡¥ø‡¥Ç‡¥ó‡µç (Simplified Loading)
# ---------------------------------

# @st.cache_resource # üö® ‡¥ï‡¥æ‡¥∑‡µÜ ‡¥™‡µÇ‡µº‡¥£‡µç‡¥£‡¥Æ‡¥æ‡¥Ø‡µÅ‡¥Ç ‡¥í‡¥¥‡¥ø‡¥µ‡¥æ‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ üö®
def load_nlp_model():
    """SpaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥±‡¥ø‡¥™‡µç‡¥™‡µã‡¥∏‡¥ø‡¥±‡µç‡¥±‡¥±‡¥ø‡¥Ø‡¥ø‡µΩ ‡¥®‡¥ø‡¥®‡µç‡¥®‡µç ‡¥®‡µá‡¥∞‡¥ø‡¥ü‡µç‡¥ü‡µç ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ."""
    try:
        nlp = spacy.load("en_core_web_sm") 
        # st.success("SpaCy model loaded successfully from repository!") # Success msg ‡¥í‡¥¥‡¥ø‡¥µ‡¥æ‡¥ï‡µç‡¥ï‡¥æ‡¥Ç
        return nlp
    except OSError as e:
        # ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡µª ‡¥∏‡¥æ‡¥ß‡¥ø‡¥ö‡µç‡¥ö‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥™‡¥ø‡¥∂‡¥ï‡µç ‡¥∏‡¥®‡µç‡¥¶‡µá‡¥∂‡¥Ç ‡¥®‡µΩ‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.
        st.error(f"‚ùå Critical Error: SpaCy model not found in the repository path. Error: {e}")
        return None

# ‡¥Æ‡µã‡¥°‡µΩ, ‡¥í‡¥∞‡µÅ ‡¥§‡¥µ‡¥£, ‡¥Ü‡¥™‡µç‡¥≤‡¥ø‡¥ï‡µç‡¥ï‡µá‡¥∑‡µª ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï
nlp = load_nlp_model() 

# ---------------------------------
# 4. ‡¥™‡µç‡¥∞‡¥ß‡¥æ‡¥® Streamlit ‡¥Ø‡µÅ‡¥ê (UI)
# ---------------------------------

# nlp ‡¥Æ‡µã‡¥°‡µΩ ‡¥µ‡¥ø‡¥ú‡¥Ø‡¥ï‡¥∞‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡¥æ‡µΩ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç ‡¥¨‡¥æ‡¥ï‡µç‡¥ï‡¥ø ‡¥Ü‡¥™‡µç‡¥≤‡¥ø‡¥ï‡µç‡¥ï‡µá‡¥∑‡µª ‡¥™‡µç‡¥∞‡¥µ‡µº‡¥§‡µç‡¥§‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï
if nlp is not None:
    st.title("NLP Skill Gap Analyzer") 
    
    # ... ‡¥¨‡¥æ‡¥ï‡µç‡¥ï‡¥ø ‡¥ï‡µã‡¥°‡µÅ‡¥ï‡µæ (UI, ‡¥¨‡¥ü‡µç‡¥ü‡¥£‡µÅ‡¥ï‡µæ, ‡¥´‡¥Ç‡¥ó‡µç‡¥∑‡¥®‡µÅ‡¥ï‡µæ) ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ ‡¥µ‡¥∞‡¥£‡¥Ç.
    
    # ...# ---------------------------------
# 2. ‡¥ü‡µÇ‡µæ ‡¥∏‡µÜ‡¥±‡µç‡¥±‡¥™‡µç‡¥™‡µÅ‡¥Ç ‡¥∏‡µç‡¥ï‡¥ø‡µΩ ‡¥≤‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç
# ---------------------------------
# ---------------------------------
TECH_SKILLS = [
    "python", "java", "sql", "aws", "azure", "docker", "kubernetes", "javascript", 
    "html", "css", "mongodb", "react", "angular", "nlp", "machine learning", 
    "deep learning", "tableau", "power bi", "hadoop", "c++", "pandas", "numpy", 
    "data analysis", "cloud computing"
]
SOFT_SKILLS = [
    "communication", "leadership", "teamwork", "problem solving", "time management", 
    "creativity", "adaptability", "mentoring", "management", "agile", "scrum", 
    "public speaking", "presentation"
]

SKILL_MAPPING = {
    'analytical thinking': 'problem solving', 'analytical skills': 'problem solving',
    'data visualization': 'tableau', 'nosql': 'mongodb', 'cloud services': 'aws', 
    'cloud platforms': 'aws', 'deep learning': 'machine learning', 
    'working with team': 'teamwork', 'team player': 'teamwork', 
    'public speaking': 'communication', 'time organizing': 'time management',
    'group projects': 'teamwork', 'business intelligence': 'power bi',
    'cloud computing': 'aws', 'strong communication': 'communication', 
    'presentation skills': 'presentation' 
}

ALL_SKILLS = [s.lower() for s in TECH_SKILLS + SOFT_SKILLS]

# ---------------------------------
# 3. spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡¥ø‡¥Ç‡¥ó‡µç (‡¥í‡¥∞‡µä‡¥±‡µç‡¥± ‡¥§‡¥µ‡¥£ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç)
# ---------------------------------

@st.cache_resource 
def load_nlp_model():
    """SpaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥∏‡µÅ‡¥∞‡¥ï‡µç‡¥∑‡¥ø‡¥§‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ."""
    try:
        # requirements.txt ‡¥µ‡¥¥‡¥ø ‡¥á‡µª‡¥∏‡µç‡¥±‡µç‡¥±‡¥æ‡µæ ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥Æ‡µã‡¥°‡µΩ ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
        nlp = spacy.load("en_core_web_sm") 
        return nlp
    except OSError:
        # ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡µª ‡¥∏‡¥æ‡¥ß‡¥ø‡¥ö‡µç‡¥ö‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥™‡¥ø‡¥¥‡¥µ‡µç ‡¥ï‡¥æ‡¥£‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï
        st.error("‚ùå SpaCy model 'en_core_web_sm' failed to load. Please ensure the model installation link in 'requirements.txt' is correct.")
        return None

nlp = load_nlp_model() # ‡¥í‡¥∞‡µÅ ‡¥§‡¥µ‡¥£ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ

# ---------------------------------
# 4. ‡¥´‡¥Ç‡¥ó‡µç‡¥∑‡¥®‡µÅ‡¥ï‡µæ (Text Extraction, Skill Extraction, Comparison)
# ---------------------------------

def extract_text_from_pdf(uploaded_file):
    text = ""
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
        return text
    except Exception as e:
        st.error(f"‚ùå Error reading PDF file: {e}")
        return None

def extract_skills_from_text(text, skill_list):
    # nlp ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥±‡µ∫ ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡µç ‡¥í‡¥¥‡¥ø‡¥µ‡¥æ‡¥ï‡µç‡¥ï‡µÅ‡¥ï
    if not nlp or not text:
        return set()
        
    processed_text = text.lower()
    doc = nlp(processed_text)
    raw_found_skills = set() 
    
    # RAW EXTRACTION ‡¥≤‡µã‡¥ú‡¥ø‡¥ï‡µç‡¥ï‡µç (Noun Chunks, Tokens, Phrase Matching)
    for chunk in doc.noun_chunks:
        chunk_text = chunk.text.lower()
        if chunk_text in skill_list:
            raw_found_skills.add(chunk_text)
            
    for token in doc:
        token_text = token.text.lower()
        if token_text in skill_list and len(token_text) > 2: 
            raw_found_skills.add(token_text)
            
    for skill in skill_list:
        if len(skill.split()) > 1:
            if skill in processed_text:
                raw_found_skills.add(skill)

    # MAPPING: Synonyms ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥Æ‡¥æ‡¥∏‡µç‡¥±‡µç‡¥±‡µº ‡¥∏‡µç‡¥ï‡¥ø‡¥≤‡µç‡¥≤‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡µÅ‡¥®‡µç‡¥®‡µÅ
    final_mapped_skills = set()
    for skill in raw_found_skills:
        if skill in SKILL_MAPPING: 
            final_mapped_skills.add(SKILL_MAPPING[skill])
        else:
            final_mapped_skills.add(skill)
            
    return final_mapped_skills 

def compare_skills(resume_skills, required_jd_skills):
    matching_skills = resume_skills.intersection(required_jd_skills)
    missing_skills = required_jd_skills.difference(resume_skills)
    extra_skills = resume_skills.difference(required_jd_skills)
    
    return {
        "Matching Skills": matching_skills,
        "Missing Skills": missing_skills,
        "Extra Skills": extra_skills
    }

# ---------------------------------
# 5. STREAMLIT UI/MAIN APP
# ---------------------------------

st.set_page_config(page_title="Skill Gap Analyzer", layout="wide")
st.title("ü§ñ NLP Skill Gap Analyzer")
st.markdown("Upload a Job Description (TXT) and a Resume (PDF) to get a skill gap report.")

col1, col2 = st.columns(2)

with col1:
    jd_file = st.file_uploader("Upload Job Description (TXT)", type=["txt"])
with col2:
    resume_file = st.file_uploader("Upload Resume (PDF)", type=["pdf"])

if jd_file and resume_file:
    # JD Text ‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ (utf-8 ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ)
    try:
        jd_text = jd_file.read().decode('utf-8')
    except Exception as e:
        st.error(f"‚ùå Error reading JD file: {e}")
        jd_text = ""
        
    # Resume Text ‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
    resume_text = extract_text_from_pdf(resume_file)

    # ‡¥Æ‡µã‡¥°‡µΩ ‡¥µ‡¥ø‡¥ú‡¥Ø‡¥ï‡¥∞‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡¥æ‡µΩ ‡¥Æ‡¥æ‡¥§‡µç‡¥∞‡¥Ç ‡¥µ‡¥ø‡¥∂‡¥ï‡¥≤‡¥®‡¥Ç ‡¥§‡µÅ‡¥ü‡¥ô‡µç‡¥ô‡µÅ‡¥ï
    if nlp and jd_text and resume_text:
        with st.spinner("Analyzing skills..."):
            jd_skills_required = extract_skills_from_text(jd_text, ALL_SKILLS)
            resume_skills_got = extract_skills_from_text(resume_text, ALL_SKILLS)
            gap_report = compare_skills(resume_skills_got, jd_skills_required)

        st.success("‚úÖ Analysis Complete!")
        
        # 1. Summary Metrics
        st.metric(label="Matching Score", value=f"{len(gap_report['Matching Skills'])} / {len(jd_skills_required)}", 
                  delta=f"-{len(gap_report['Missing Skills'])} Missing Skills")

        # 2. Detailed Report
        st.header("Detailed Skill Gap Analysis")

        # Missing Skills
        st.subheader(f"‚ùå Missing Skills (GAP: {len(gap_report['Missing Skills'])})")
        if gap_report['Missing Skills']:
            st.warning(", ".join(sorted(list(gap_report['Missing Skills']))))
        else:
            st.success("No missing required skills found!")

        # Matching Skills
        st.subheader(f"‚úî Matching Skills ({len(gap_report['Matching Skills'])})")
        st.info(", ".join(sorted(list(gap_report['Matching Skills']))))

        # Extra Skills
        st.subheader(f"‚≠ê Extra Skills (Not required: {len(gap_report['Extra Skills'])})")
        st.code(", ".join(sorted(list(gap_report['Extra Skills']))))

    elif not nlp:
        # ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡µª ‡¥™‡¥±‡µç‡¥±‡¥ø‡¥Ø‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ
        st.error("Analysis Failed. Cannot proceed without the SpaCy model.")
    else:
        st.warning("Please upload valid files to start the analysis.")




