# ==============================================================================
# Streamlit APP CODE (app.py)
# = ============================================================================

# 1. ‡¥Ü‡¥µ‡¥∂‡µç‡¥Ø‡¥Æ‡¥æ‡¥Ø ‡¥≤‡µà‡¥¨‡µç‡¥∞‡¥±‡¥ø‡¥ï‡µæ ‡¥á‡¥±‡¥ï‡µç‡¥ï‡µÅ‡¥Æ‡¥§‡¥ø ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï
import subprocess
try:
    subprocess.run(["python", "-m", "spacy", "download", "en_core_web_sm"], check=True)
except:
    pass # ‡¥á‡µª‡¥∏‡µç‡¥±‡µç‡¥±‡¥æ‡µæ ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡¥ø‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥Æ‡µÅ‡¥®‡µç‡¥®‡µã‡¥ü‡µç‡¥ü‡µç ‡¥™‡µã‡¥ï‡µÅ‡¥ï.
import streamlit as st # Streamlit ‡¥≤‡µà‡¥¨‡µç‡¥∞‡¥±‡¥ø
import PyPDF2
import spacy
import re
import os
from spacy.matcher import Matcher
# ---------------------------------
# spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ
@st.cache_resource # ‡¥á‡¥§‡µç ‡¥Æ‡µã‡¥°‡µΩ ‡¥í‡¥∞‡µá‡¥Ø‡µä‡¥∞‡µÅ ‡¥§‡¥µ‡¥£ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡µª ‡¥∏‡¥π‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
def load_model():
    try:
        # ‡¥®‡¥Æ‡µç‡¥Æ‡µæ requirements.txt ‡¥µ‡¥¥‡¥ø ‡¥á‡µª‡¥∏‡µç‡¥±‡µç‡¥±‡¥æ‡µæ ‡¥ö‡µÜ‡¥Ø‡µç‡¥§ ‡¥Æ‡µã‡¥°‡µΩ ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
        nlp = spacy.load("en_core_web_sm")
        return nlp
    except OSError:
        st.error("SpaCy model 'en_core_web_sm' could not be loaded.")
        return None

nlp = load_model()
# ---------------------------------
# ---------------------------------
# 2. ‡¥ü‡µÇ‡µæ ‡¥∏‡µÜ‡¥±‡µç‡¥±‡¥™‡µç‡¥™‡µÅ‡¥Ç ‡¥∏‡µç‡¥ï‡¥ø‡µΩ ‡¥≤‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡µÅ‡¥Ç (‡¥ó‡µç‡¥≤‡µã‡¥¨‡µΩ ‡¥µ‡µá‡¥∞‡¥ø‡¥Ø‡¥¨‡¥ø‡¥≥‡µÅ‡¥ï‡µæ)
# ---------------------------------
# ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥∏‡µç‡¥ï‡¥ø‡µΩ ‡¥≤‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç ‡¥Æ‡¥æ‡¥™‡µç‡¥™‡¥ø‡¥Ç‡¥ó‡µÅ‡¥ï‡¥≥‡µÅ‡¥Ç ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ ‡¥ö‡µá‡µº‡¥ï‡µç‡¥ï‡µÅ‡¥ï (‡¥Æ‡µÅ‡¥Æ‡µç‡¥™‡¥§‡µç‡¥§‡µÜ ‡¥ï‡µã‡¥°‡¥ø‡µΩ ‡¥®‡¥ø‡¥®‡µç‡¥®‡µç ‡¥ï‡µã‡¥™‡µç‡¥™‡¥ø ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï)
TECH_SKILLS = [
    "python", "java", "sql", "aws", "azure", "docker", "kubernetes", 
    "javascript", "html", "css", "mongodb", "react", "angular", "nlp", 
    "machine learning", "deep learning", "tableau", "power bi", "hadoop", "c++",
    "pandas", "numpy", "data analysis", "cloud computing"
]
SOFT_SKILLS = [
    "communication", "leadership", "teamwork", "problem solving", 
    "time management", "creativity", "adaptability", "mentoring", 
    "management", "agile", "scrum", "public speaking", "presentation"
]

SKILL_MAPPING = {
    'analytical thinking': 'problem solving', 'analytical skills': 'problem solving',
    'data visualization': 'tableau', 'nosql': 'mongodb', 'cloud services': 'aws', 
    'cloud platforms': 'aws', 'deep learning': 'machine learning', 
    'working with team': 'teamwork', 'team player': 'teamwork', 
    'public speaking': 'communication', 'time organizing': 'time management',
    'group projects': 'teamwork', 'business intelligence': 'power bi',
    'cloud computing': 'aws', 'strong communication': 'communication', 
    'presentation skills': 'presentation' 
}

ALL_SKILLS = [s.lower() for s in TECH_SKILLS + SOFT_SKILLS]

# spaCy ‡¥Æ‡µã‡¥°‡µΩ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ
@st.cache_resource # ‡¥á‡¥§‡µç ‡¥Æ‡µã‡¥°‡µΩ ‡¥í‡¥∞‡µá‡¥Ø‡µä‡¥∞‡µÅ ‡¥§‡¥µ‡¥£ ‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡µª ‡¥∏‡¥π‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
def load_model():
    try:
        nlp = spacy.load("en_core_web_sm")
        return nlp
    except OSError:
        # Streamlit Cloud-‡µΩ ‡¥™‡µç‡¥∞‡¥µ‡µº‡¥§‡µç‡¥§‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ ‡¥Æ‡µã‡¥°‡µΩ ‡¥°‡µó‡µ∫‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡¥æ‡¥®‡µÅ‡¥≥‡µç‡¥≥ ‡¥∏‡¥æ‡¥ß‡µç‡¥Ø‡¥§
        # Streamlit-‡¥®‡µç ‡¥Ü‡¥µ‡¥∂‡µç‡¥Ø‡¥Æ‡¥æ‡¥Ø "requirements.txt" ‡¥´‡¥Ø‡¥≤‡¥ø‡¥≤‡¥æ‡¥£‡µç ‡¥à ‡¥Æ‡µã‡¥°‡µΩ ‡¥â‡µæ‡¥™‡µç‡¥™‡µÜ‡¥ü‡µÅ‡¥§‡µç‡¥§‡µá‡¥£‡µç‡¥ü‡¥§‡µç.
        st.error("SpaCy model 'en_core_web_sm' not loaded. Check requirements.")
        return None

nlp = load_model()

# ---------------------------------
# 3. ‡¥´‡¥Ç‡¥ó‡µç‡¥∑‡¥®‡µÅ‡¥ï‡µæ (Jupyter-‡µΩ ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ö‡µç‡¥ö ‡¥Ö‡¥§‡µá ‡¥´‡¥Ç‡¥ó‡µç‡¥∑‡¥®‡µÅ‡¥ï‡µæ)
# ---------------------------------

def extract_text_from_pdf(uploaded_file):
    # Streamlit-‡µΩ ‡¥´‡¥Ø‡µΩ ‡¥Ö‡¥™‡µç‚Äå‡¥≤‡µã‡¥°‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥Æ‡µç‡¥™‡µã‡µæ ‡¥á‡¥§‡µç file buffer ‡¥Ü‡¥Ø‡¥ø‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥Ç
    text = ""
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
        return text
    except Exception as e:
        st.error(f"Error reading PDF file: {e}")
        return None

def extract_skills_from_text(text, skill_list):
    if not nlp or not text:
        return set()
    
    processed_text = text.lower()
    doc = nlp(processed_text)
    raw_found_skills = set() 
    
    # RAW EXTRACTION ‡¥≤‡µã‡¥ú‡¥ø‡¥ï‡µç‡¥ï‡µç
    for chunk in doc.noun_chunks:
        chunk_text = chunk.text.lower()
        if chunk_text in skill_list:
            raw_found_skills.add(chunk_text)
            
    for token in doc:
        token_text = token.text.lower()
        if token_text in skill_list and len(token_text) > 2: 
            raw_found_skills.add(token_text)
            
    for skill in skill_list:
        if len(skill.split()) > 1:
            if skill in processed_text:
                raw_found_skills.add(skill)

    # MAPPING: Synonyms ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥Æ‡¥æ‡¥∏‡µç‡¥±‡µç‡¥±‡µº ‡¥∏‡µç‡¥ï‡¥ø‡¥≤‡µç‡¥≤‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µç ‡¥Æ‡¥æ‡¥±‡µç‡¥±‡µÅ‡¥®‡µç‡¥®‡µÅ
    final_mapped_skills = set()
    for skill in raw_found_skills:
        if skill in SKILL_MAPPING: 
            final_mapped_skills.add(SKILL_MAPPING[skill])
        else:
            final_mapped_skills.add(skill)
            
    return final_mapped_skills 

# ---------------------------------
# 5. Comparison Logic: ‡¥§‡¥æ‡¥∞‡¥§‡¥Æ‡µç‡¥Ø‡¥Ç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥ï (‡¥á‡¥§‡µç app.py-‡¥Ø‡¥ø‡µΩ ‡¥ö‡µá‡µº‡¥ï‡µç‡¥ï‡µÅ‡¥ï)
# ---------------------------------

def compare_skills(resume_skills, required_jd_skills):
    # ‡¥∏‡µÜ‡¥±‡µç‡¥±‡µç ‡¥ì‡¥™‡µç‡¥™‡¥±‡µá‡¥∑‡¥®‡µÅ‡¥ï‡µæ ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥§‡¥æ‡¥∞‡¥§‡¥Æ‡µç‡¥Ø‡¥Ç
    matching_skills = resume_skills.intersection(required_jd_skills)
    missing_skills = required_jd_skills.difference(resume_skills)
    extra_skills = resume_skills.difference(required_jd_skills)
    
    return {
        "Matching Skills": matching_skills,
        "Missing Skills": missing_skills,
        "Extra Skills": extra_skills
    }

# ---------------------------------
# 4. STREAMLIT UI/MAIN APP
# ---------------------------------

st.set_page_config(page_title="Skill Gap Analyzer", layout="wide")
st.title("ü§ñ NLP Skill Gap Analyzer")
st.markdown("Upload a Job Description (TXT) and a Resume (PDF) to get a skill gap report.")

# ‡¥á‡µª‡¥™‡µÅ‡¥ü‡µç‡¥ü‡µç ‡¥è‡¥∞‡¥ø‡¥Ø‡¥ï‡µæ
col1, col2 = st.columns(2)

with col1:
    jd_file = st.file_uploader("Upload Job Description (TXT)", type=["txt"])
with col2:
    resume_file = st.file_uploader("Upload Resume (PDF)", type=["pdf"])

if jd_file and resume_file:
    # JD Text ‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ (utf-8 ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ)
    try:
        jd_text = jd_file.read().decode('utf-8')
    except Exception as e:
        st.error(f"Error reading JD file: {e}")
        jd_text = ""
        
    # Resume Text ‡¥µ‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ
    resume_text = extract_text_from_pdf(resume_file)

    if jd_text and resume_text:
        with st.spinner("Analyzing skills..."):
            # A. JD Skills
            jd_skills_required = extract_skills_from_text(jd_text, ALL_SKILLS)
            
            # B. Resume Skills
            resume_skills_got = extract_skills_from_text(resume_text, ALL_SKILLS)
            
            # C. Comparison
            gap_report = compare_skills(resume_skills_got, jd_skills_required)

        # -------------------
        # ‡¥±‡¥ø‡¥™‡µç‡¥™‡µã‡µº‡¥ü‡µç‡¥ü‡µç ‡¥î‡¥ü‡µç‡¥ü‡µç‡¥™‡µÅ‡¥ü‡µç‡¥ü‡µç (Report Output)
        # -------------------
        st.success("‚úÖ Analysis Complete!")
        
        # 1. Summary Metrics
        st.metric(label="Matching Score", value=f"{len(gap_report['Matching Skills'])} / {len(jd_skills_required)}", 
                  delta=f"-{len(gap_report['Missing Skills'])} Missing Skills")

        # 2. Detailed Report
        st.header("Detailed Skill Gap Analysis")

        # Missing Skills
        st.subheader(f"‚ùå Missing Skills (GAP: {len(gap_report['Missing Skills'])})")
        if gap_report['Missing Skills']:
            st.warning(", ".join(sorted(list(gap_report['Missing Skills']))))
        else:
            st.success("No missing required skills found!")

        # Matching Skills
        st.subheader(f"‚úî Matching Skills ({len(gap_report['Matching Skills'])})")
        st.info(", ".join(sorted(list(gap_report['Matching Skills']))))

        # Extra Skills
        st.subheader(f"‚≠ê Extra Skills (Not required: {len(gap_report['Extra Skills'])})")
        st.code(", ".join(sorted(list(gap_report['Extra Skills']))))

    else:
        st.warning("Please upload valid files to start the analysis.")

# ==============================================================================
